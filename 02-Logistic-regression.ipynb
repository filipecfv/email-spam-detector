{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9e5bb5e-acbc-4442-8132-bbc80d1a54c1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2eea143-4f51-4259-bf30-a95a70b7845b",
   "metadata": {},
   "source": [
    "The logistic regression model is a simple linear model yet very useful to predict and analyse behavior between data where the endogenous variable (i.e., the dependent or explained variable, or simply the variable we want to predict, in this case whether a email is spam or not) is dichotomous, assuming only 0 and 1 values. \n",
    "\n",
    "Some advantages and disadvantages of using logistic regression are:\n",
    "\n",
    "Pros:\n",
    "- Simple and straightforward.\n",
    "- Easy to interpret the effects of multiple independent variables on the dependent variable.\n",
    "- As it provides probability estimates to each coeficient, it is very useful in decision-making.\n",
    "\n",
    "Cons:\n",
    "- Logistic regression assumes a linear relationship between the independent variables and the log-odds of the dependent variable, which may not hold true in all situations.\n",
    "- It is sensitive to outliers and influential data points, which can affect the model's accuracy.\n",
    "- It can suffer from overfitting if there are too many independent variables relative to the number of observations in the dataset.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5f2fbe0-e5ee-4342-8f2f-c7438ead0d32",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1     2    3     4     5     6     7     8     9  ...    48   \n",
       "0  0.00  0.64  0.64  0.0  0.32  0.00  0.00  0.00  0.00  0.00  ...  0.00  \\\n",
       "1  0.21  0.28  0.50  0.0  0.14  0.28  0.21  0.07  0.00  0.94  ...  0.00   \n",
       "2  0.06  0.00  0.71  0.0  1.23  0.19  0.19  0.12  0.64  0.25  ...  0.01   \n",
       "3  0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.00   \n",
       "4  0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.00   \n",
       "\n",
       "      49   50     51     52     53     54   55    56  spam  \n",
       "0  0.000  0.0  0.778  0.000  0.000  3.756   61   278     1  \n",
       "1  0.132  0.0  0.372  0.180  0.048  5.114  101  1028     1  \n",
       "2  0.143  0.0  0.276  0.184  0.010  9.821  485  2259     1  \n",
       "3  0.137  0.0  0.137  0.000  0.000  3.537   40   191     1  \n",
       "4  0.135  0.0  0.135  0.000  0.000  3.537   40   191     1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import libraries and read dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "\n",
    "df = pd.read_csv('output/spam_email.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93256619-f603-4a53-bf5f-6658e1937744",
   "metadata": {},
   "source": [
    "## Basic Train-Test Split \n",
    "\n",
    "Split the data into a training sample with which the model will learn, and a validation (testing) sample to test its accuracy. By default, the train_test_split function sets the training sample size as 25% of the total number of observations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28f2bdbd-ddc2-4f4a-bfa9-a5545169b9ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# spliting test and train samples\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_predictors = df.drop('spam', axis = 1)\n",
    "df_predicted = df['spam']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_predictors, df_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e9e33c7-20db-475c-80e9-0612362dd899",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=2000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=2000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=2000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training the model \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "LRmodel = LogisticRegression(solver='lbfgs', max_iter=2000)\n",
    "LRmodel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d9b8699-ad91-4cbc-af3d-6dcf51fda0b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model accuracy: 0.9348392701998263\n",
      "mean squared error: 0.06516072980017376\n"
     ]
    }
   ],
   "source": [
    "# prediction score\n",
    "score = LRmodel.score(X_test, y_test)\n",
    "\n",
    "# error \n",
    "from sklearn.metrics import mean_squared_error\n",
    "error = mean_squared_error(y_test, LRmodel.predict(X_test))\n",
    "\n",
    "print('model accuracy:', score)\n",
    "print('mean squared error:', error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3231a5-5331-458d-952f-63b4135385e5",
   "metadata": {},
   "source": [
    "It means the model is capable to detect in average 93.49% of spam emails;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd615c0e-4828-498b-9429-0c8c4a5dfd36",
   "metadata": {},
   "source": [
    "# Resampling methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5d549f-6536-4208-9882-127c587187ee",
   "metadata": {},
   "source": [
    "Sometimes the original train-test split may yealds results that are not representative of the real accuracy of the model. To ensure that these results are not merely a coincidence dependent on the way the samples were splitted, we apply resampling methods. \n",
    "Resampling consists in spliting the data randomly into multiple training and testing samples, often shuffling the data, to have a more accurate validation. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df81b72-5ee5-45be-8029-1a4029764827",
   "metadata": {},
   "source": [
    "## K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a629ea-305c-4fb1-86d7-3782d46e6480",
   "metadata": {},
   "source": [
    "Cross validation consists in spliting many different training and testing samples and verifying the accuracy of the model. In practice, it means fitting the model multiple times with each different test-train split. One cross validation method commonly used is the K-Fold one for splitting a dataset into k equally sized parts.  \n",
    "\n",
    "\n",
    "We can easily retrieve the average score of a cross validation with the while cross_val_score, that automates the process of using K-Fold to perform cross-validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35360b64-834b-43e6-bf64-b9a71ffd5a5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# we specify 20 folds, i.e, 20 train-test splits and fitted models. \n",
    "scores = cross_val_score(LRmodel, X_train, y_train, \n",
    "                         cv = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a98a1aa3-7362-44a6-9df1-a2018295af36",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [0.9017341  0.94797688 0.89017341 0.90751445 0.93063584 0.90751445\n",
      " 0.94219653 0.93063584 0.89017341 0.9017341  0.90697674 0.94186047\n",
      " 0.93023256 0.93023256 0.93604651 0.93604651 0.94186047 0.95348837\n",
      " 0.93604651 0.94767442]\n",
      "\n",
      "Mean: 0.9255377066810058\n",
      "\n",
      "Std deviation: 0.019546376020078658\n"
     ]
    }
   ],
   "source": [
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"\\nMean:\", scores.mean())\n",
    "    print(\"\\nStd deviation:\", scores.std())\n",
    "\n",
    "display_scores(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d3c27d-7e43-40d8-957c-e93a70ea0d81",
   "metadata": {},
   "source": [
    "---\n",
    "Alternatively, we can do it manually with the KFold function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3587d57-49b0-4559-af9c-f9c0ddffba69",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    train  test  accuracy\n",
      "0    4370   231  0.922078\n",
      "1    4371   230  0.934783\n",
      "2    4371   230  0.917391\n",
      "3    4371   230  0.956522\n",
      "4    4371   230  0.939130\n",
      "5    4371   230  0.926087\n",
      "6    4371   230  0.913043\n",
      "7    4371   230  0.926087\n",
      "8    4371   230  0.921739\n",
      "9    4371   230  0.921739\n",
      "10   4371   230  0.943478\n",
      "11   4371   230  0.873913\n",
      "12   4371   230  0.913043\n",
      "13   4371   230  0.926087\n",
      "14   4371   230  0.930435\n",
      "15   4371   230  0.934783\n",
      "16   4371   230  0.939130\n",
      "17   4371   230  0.939130\n",
      "18   4371   230  0.934783\n",
      "19   4371   230  0.956522\n",
      "average accuracy: 0.9284952004517221\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=20, shuffle = True, random_state = 1)\n",
    "\n",
    "r_train = []\n",
    "r_test = []\n",
    "accuracy = []\n",
    "for train, test in kf.split(df):\n",
    "    # print('train: ', train.shape[0])\n",
    "    # print('test: ', test.shape[0])\n",
    "    r_train.append(train.shape[0])\n",
    "    r_test.append(test.shape[0])\n",
    "\n",
    "    X_traink, X_testk = df_predictors.iloc[train], df_predictors.iloc[test]\n",
    "    y_traink, y_testk = df_predicted.iloc[train], df_predicted.iloc[test]\n",
    "\n",
    "    LRmodel = LogisticRegression(solver='lbfgs', max_iter=3000)\n",
    "    LRmodel.fit(X_traink, y_traink)\n",
    "\n",
    "    # print('accuracy', LRmodel.score(X_testk, y_testk))\n",
    "    # print()\n",
    "\n",
    "    acc = LRmodel.score(X_testk, y_testk)\n",
    "    accuracy.append(acc)\n",
    "\n",
    "results = pd.DataFrame()\n",
    "results['train'] = r_train\n",
    "results['test'] = r_test\n",
    "results['accuracy'] = accuracy\n",
    "\n",
    "print(results)\n",
    "print('average accuracy:', results['accuracy'].mean())\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808c88da-f251-413f-89ef-c8d702191189",
   "metadata": {},
   "source": [
    "## Repeated K-Fold\n",
    "RepeatedKFold is a variant of KFold that repeats the process n times, where n is specified by the user. This can help to provide a more robust estimate of model performance by averaging across multiple iterations of the KFold process. Essentially, RepeatedKFold is useful when you want to evaluate the performance of a model across multiple randomized splits of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50b7e799-da83-4b87-9a0f-9f1387669622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_state 1\n",
      "    train  test  accuracy\n",
      "0    4370   231  0.922078\n",
      "1    4371   230  0.934783\n",
      "2    4371   230  0.917391\n",
      "3    4371   230  0.956522\n",
      "4    4371   230  0.939130\n",
      "5    4371   230  0.926087\n",
      "6    4371   230  0.913043\n",
      "7    4371   230  0.926087\n",
      "8    4371   230  0.921739\n",
      "9    4371   230  0.921739\n",
      "10   4371   230  0.943478\n",
      "11   4371   230  0.873913\n",
      "12   4371   230  0.913043\n",
      "13   4371   230  0.926087\n",
      "14   4371   230  0.930435\n",
      "15   4371   230  0.934783\n",
      "16   4371   230  0.939130\n",
      "17   4371   230  0.939130\n",
      "18   4371   230  0.934783\n",
      "19   4371   230  0.956522\n",
      "average accuracy: 0.9284952004517221\n",
      "\n",
      "random_state 2\n",
      "    train  test  accuracy\n",
      "0    4370   231  0.948052\n",
      "1    4371   230  0.960870\n",
      "2    4371   230  0.886957\n",
      "3    4371   230  0.917391\n",
      "4    4371   230  0.913043\n",
      "5    4371   230  0.913043\n",
      "6    4371   230  0.956522\n",
      "7    4371   230  0.930435\n",
      "8    4371   230  0.960870\n",
      "9    4371   230  0.926087\n",
      "10   4371   230  0.956522\n",
      "11   4371   230  0.891304\n",
      "12   4371   230  0.917391\n",
      "13   4371   230  0.917391\n",
      "14   4371   230  0.913043\n",
      "15   4371   230  0.921739\n",
      "16   4371   230  0.939130\n",
      "17   4371   230  0.930435\n",
      "18   4371   230  0.947826\n",
      "19   4371   230  0.952174\n",
      "average accuracy: 0.9300112930547713\n",
      "\n",
      "random_state 3\n",
      "    train  test  accuracy\n",
      "0    4370   231  0.887446\n",
      "1    4371   230  0.947826\n",
      "2    4371   230  0.978261\n",
      "3    4371   230  0.921739\n",
      "4    4371   230  0.900000\n",
      "5    4371   230  0.930435\n",
      "6    4371   230  0.926087\n",
      "7    4371   230  0.917391\n",
      "8    4371   230  0.934783\n",
      "9    4371   230  0.943478\n",
      "10   4371   230  0.904348\n",
      "11   4371   230  0.921739\n",
      "12   4371   230  0.939130\n",
      "13   4371   230  0.921739\n",
      "14   4371   230  0.943478\n",
      "15   4371   230  0.917391\n",
      "16   4371   230  0.943478\n",
      "17   4371   230  0.908696\n",
      "18   4371   230  0.921739\n",
      "19   4371   230  0.934783\n",
      "average accuracy: 0.9271983813288163\n",
      "\n",
      "random_state 4\n",
      "    train  test  accuracy\n",
      "0    4370   231  0.900433\n",
      "1    4371   230  0.921739\n",
      "2    4371   230  0.947826\n",
      "3    4371   230  0.952174\n",
      "4    4371   230  0.926087\n",
      "5    4371   230  0.960870\n",
      "6    4371   230  0.913043\n",
      "7    4371   230  0.900000\n",
      "8    4371   230  0.947826\n",
      "9    4371   230  0.917391\n",
      "10   4371   230  0.926087\n",
      "11   4371   230  0.956522\n",
      "12   4371   230  0.921739\n",
      "13   4371   230  0.930435\n",
      "14   4371   230  0.895652\n",
      "15   4371   230  0.939130\n",
      "16   4371   230  0.917391\n",
      "17   4371   230  0.943478\n",
      "18   4371   230  0.908696\n",
      "19   4371   230  0.926087\n",
      "average accuracy: 0.927630340673819\n",
      "\n",
      "final average accuracy among folds: 0.9283338038772821\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "acc_mean = []\n",
    "for rep in range(1, 5): \n",
    "    kf = KFold(n_splits=20, shuffle = True, random_state = rep)\n",
    "\n",
    "    r_train = []\n",
    "    r_test = []\n",
    "    accuracy = []\n",
    "    for train, test in kf.split(df):\n",
    "        # print('train: ', train.shape[0])\n",
    "        # print('test: ', test.shape[0])\n",
    "        r_train.append(train.shape[0])\n",
    "        r_test.append(test.shape[0])\n",
    "\n",
    "        X_traink, X_testk = df_predictors.iloc[train], df_predictors.iloc[test]\n",
    "        y_traink, y_testk = df_predicted.iloc[train], df_predicted.iloc[test]\n",
    "\n",
    "        LRmodel = LogisticRegression(solver='lbfgs', max_iter=3000)\n",
    "        LRmodel.fit(X_traink, y_traink)\n",
    "\n",
    "        # print('accuracy', LRmodel.score(X_testk, y_testk))\n",
    "        # print()\n",
    "\n",
    "        acc = LRmodel.score(X_testk, y_testk)\n",
    "        accuracy.append(acc)\n",
    "\n",
    "    results = pd.DataFrame()\n",
    "    results['train'] = r_train\n",
    "    results['test'] = r_test\n",
    "    results['accuracy'] = accuracy\n",
    "    \n",
    "    print('random_state', rep)\n",
    "    print(results)\n",
    "    print('average accuracy:', results['accuracy'].mean())\n",
    "    print()\n",
    "    ac = results['accuracy'].mean()\n",
    "    acc_mean.append(ac)\n",
    "\n",
    "print('final average accuracy among folds:', np.mean(acc_mean))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
